{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-19T18:16:05.050146",
     "start_time": "2016-07-19T18:16:05.043483"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 380000\n",
    "vector_size = 200\n",
    "num_topics = 256\n",
    "word_vectors = vocabulary_size * vector_size\n",
    "topic_vectors = num_topics * vector_size\n",
    "dot_product_values = num_topics * vocabulary_size\n",
    "exp_dot_product_values = num_topics * vocabulary_size\n",
    "\n",
    "all_together = (word_vectors + topic_vectors + dot_product_values + exp_dot_product_values) * 8.0 / (1024 * 1024)\n",
    "all_together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Spearmint for analogy reasoning\n",
    "* Gaussian LDA\n",
    "* Evaluate word analogy reasoning\n",
    "* evalutate topic models\n",
    "* find background noise\n",
    "* find word pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-19T18:46:39.620845",
     "start_time": "2016-07-19T18:46:38.228700"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import itertools\n",
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "import gensim\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pnd\n",
    "from sklearn.cluster import *\n",
    "from sklearn.decomposition import PCA, RandomizedPCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from knub.thesis.util import *\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-19T18:46:39.990387",
     "start_time": "2016-07-19T18:46:39.985196"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.text_cell_render p, div.text_cell_render ul, table.dataframe {\n",
       "font-size:1.3em;\n",
       "line-height:1.1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "div.text_cell_render p, div.text_cell_render ul, table.dataframe {\n",
    "font-size:1.3em;\n",
    "line-height:1.1em;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-19T18:47:42.529539",
     "start_time": "2016-07-19T18:47:42.526845"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL = \"../models/topic-models/topic.full.alpha-1-100.256-400.model\"\n",
    "MODEL = \"../models/topic-models/topic.256-400.first-2000.alpha-001.beta-001.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-19T18:48:45.387399",
     "start_time": "2016-07-19T18:48:20.570376"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load vectors\n",
      "Load topic probs\n",
      "Load topics\n"
     ]
    }
   ],
   "source": [
    "print \"Load vectors\"\n",
    "vectors = load_skip_gram()\n",
    "model = TopicModelLoader(MODEL, vectors)\n",
    "print \"Load topic probs\"\n",
    "df_topic_probs_full = model.load_topic_probs()\n",
    "print \"Load topics\"\n",
    "df_topics = model.load_topics()\n",
    "#print \"Load topic similars\"\n",
    "#df_topic_similars = model.load_all_topic_similars()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Probs Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-19T18:48:50.595229",
     "start_time": "2016-07-19T18:48:50.466505"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topic_probs = df_topic_probs_full[df_topic_probs_full[\"word\"].apply(lambda w: w in model.topic_words)].copy()\n",
    "df_topic_probs[\"stddev\"] = df_topic_probs[model.prob_columns].std(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word-prob does not sum to one, because we only write out frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-19T19:00:23.779325",
     "start_time": "2016-07-19T19:00:23.775017"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9596501221011898"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_probs_full[\"word-prob\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-19T18:48:52.375102",
     "start_time": "2016-07-19T18:48:52.354982"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1.0\n",
       "2    1.0\n",
       "5    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_probs.head(3)[model.prob_columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-19T18:28:50.274071",
     "start_time": "2016-07-19T18:26:51.066702"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def topic_prob_difference_from_first_to(row, n):\n",
    "    s = sorted(row, reverse=True)\n",
    "    return s[0] - s[n - 1]\n",
    "    \n",
    "\n",
    "for diff in [2, 5, 50]:\n",
    "    column_name = \"diff-\" + str(diff)\n",
    "    df_topic_probs_full[column_name] = df_topic_probs_full[model.prob_columns].apply(\n",
    "        partial(topic_prob_difference_from_first_to, n=diff), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strength of topic prevalence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Against second best topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-19T18:29:34.778845",
     "start_time": "2016-07-19T18:29:34.679411"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df_topic_probs_full[\"diff-2\"].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Against fifth best topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-19T18:35:15.436987",
     "start_time": "2016-07-19T18:35:15.320669"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df_topic_probs_full[\"diff-5\"].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Against fiftieth best topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-19T18:35:22.184210",
     "start_time": "2016-07-19T18:35:22.059301"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df_topic_probs_full[\"diff-50\"].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-19T18:51:41.130542",
     "start_time": "2016-07-19T18:51:40.368564"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word-prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>also</td>\n",
       "      <td>0.004701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>first</td>\n",
       "      <td>0.004131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>one</td>\n",
       "      <td>0.003596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>new</td>\n",
       "      <td>0.003485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>two</td>\n",
       "      <td>0.002920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>time</td>\n",
       "      <td>0.002149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>school</td>\n",
       "      <td>0.002056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>years</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>may</td>\n",
       "      <td>0.001904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>later</td>\n",
       "      <td>0.001726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  word-prob\n",
       "188    also   0.004701\n",
       "430   first   0.004131\n",
       "169     one   0.003596\n",
       "797     new   0.003485\n",
       "302     two   0.002920\n",
       "483    time   0.002149\n",
       "279  school   0.002056\n",
       "951   years   0.001993\n",
       "35      may   0.001904\n",
       "412   later   0.001726"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_probs_full.sort_values(by=\"word-prob\", ascending=False).head(10)[[\"word\", \"word-prob\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest std. dev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-14T17:24:34.427978",
     "start_time": "2016-07-14T17:24:34.367499"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topic_probs.sort_values(by=\"stddev\", ascending=False).head(10)[[\"word\", \"stddev\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowest std. dev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-14T17:24:34.488343",
     "start_time": "2016-07-14T17:24:34.430993"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topic_probs.sort_values(by=\"stddev\", ascending=True).head(10)[[\"word\", \"stddev\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Correlation TM similarity and WE similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ten most similar words for each top-10-topic word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Topic model similarity evaluated using different probability distribution similarity measures (evaluated on the normalized word-topic distributions):\n",
    " \n",
    " * [Jensen-Shannon divergence](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence)\n",
    " * Hellinger distance\n",
    " * Bhattacharyya coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-14T17:24:34.551850",
     "start_time": "2016-07-14T17:24:34.494145"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_topic_similars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-07T11:26:33.614243",
     "start_time": "2016-07-07T11:26:33.612099"
    }
   },
   "source": [
    "### Correlation between TM and WE similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-14T17:24:34.708573",
     "start_time": "2016-07-14T17:24:34.553930"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.sim_functions = [\"max\", \"sum\", \"bhattacharyya\", \"hellinger\", \"jensen-shannon\"]\n",
    "\n",
    "sim_corrs_spearman = []\n",
    "sim_corrs_pearson = []\n",
    "for sim_function in model.sim_functions:\n",
    "    corr_spearman = df_topic_similars[[\"tm_sim_%s\" % sim_function, \"we_sim\"]].corr(\"spearman\").ix[0,1]\n",
    "    corr_pearson = df_topic_similars[[\"tm_sim_%s\" % sim_function, \"we_sim\"]].corr(\"pearson\").ix[0,1]\n",
    "    sim_corrs_spearman.append(corr_spearman)\n",
    "    sim_corrs_pearson.append(corr_pearson)\n",
    "\n",
    "df_tmp = pnd.DataFrame(model.sim_functions, columns=[\"sim_function\"])\n",
    "df_tmp[\"sim_corr_spearman\"] = sim_corrs_spearman\n",
    "df_tmp[\"sim_corr_pearson\"] = sim_corrs_pearson\n",
    "df_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Similar results Google vectors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of TM similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-15T13:54:34.344525",
     "start_time": "2016-07-15T13:54:33.891360"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df_topic_similars[\"tm_sim_jensen-shannon\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of WE similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-15T13:54:37.057041",
     "start_time": "2016-07-15T13:54:36.897653"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df_topic_similars[\"we_sim\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-14T17:24:35.377135",
     "start_time": "2016-07-14T17:24:35.360935"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "we_percentile = df_topic_similars[\"we_sim\"].quantile(q=.30)\n",
    "we_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-15T13:54:40.514424",
     "start_time": "2016-07-15T13:54:40.296883"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tmp = df_topic_probs[[\"word\", \"stddev\"]]\n",
    "df_tmp.columns = [\"w\", \"stddev\"]\n",
    "df_result = df_topic_similars.merge(df_tmp, left_on=\"similar_word\", right_on=\"w\")\n",
    "del df_result[\"w\"]\n",
    "word_prob_quantile = df_result[\"stddev\"].quantile(0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High TM similarity, low WE similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-15T13:54:41.710237",
     "start_time": "2016-07-15T13:54:41.552031"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_large_sim_diff = df_result[(df_result[\"we_sim\"] < 0.4) & (df_result[\"stddev\"] > 0.025)]\n",
    "df_large_sim_diff.iloc[np.random.permutation(len(df_large_sim_diff))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High TM similarity, high WE similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-14T17:24:35.614754",
     "start_time": "2016-07-14T17:24:35.534554"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_small_sim_diff = df_result[(df_result[\"we_sim\"] > 0.8) & (df_result[\"stddev\"] > 0.025)]\n",
    "df_small_sim_diff.iloc[np.random.permutation(len(df_small_sim_diff))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* syntatic variations play a bigger role in WE models, example:\n",
    "\n",
    "  **(development, developed)**: TM-sim: 0.960519 WE-SIM: 0.360895\n",
    "  \n",
    "  **(composed, composers)** TM-SIM: 0.973376 WE-SIM: 0.329483\n",
    "  \n",
    "  **(works, working)** TM-SIM: 0.969470 WE-SIM: 0.274090\n",
    "* topic models are better at capturing loose relationships, such as:\n",
    "\n",
    "  **(war, commander)** TM-SIM: 0.922352 WE-SIM: 0.187498\n",
    "  \n",
    "  **(living, households)** TM-SIM: 0.983162 WE-SIM: 0.207906\n",
    "  \n",
    "  **(county, rural)** TM-SIM: 0.882099 WE-SIM: 0.257984\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Concept categorization in TM and WE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly the same results after using the same algorithm for both systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-15T13:55:16.615375",
     "start_time": "2016-07-15T13:55:14.827886"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_embedding_from_word_embedding(word):\n",
    "    try:\n",
    "        return vectors[word]\n",
    "    except:\n",
    "        return vectors[\"this\"]\n",
    "\n",
    "columns = [str(i) for i in range(256)]\n",
    "def get_embedding_from_topics(word):\n",
    "    df_row = df_topic_probs_full[df_topic_probs_full[\"word\"] == word]\n",
    "    assert len(df_row) == 1, \"not exactly one row found: \" + word + \" \" + len(df_row)\n",
    "    return df_row[columns].iloc[0,:].tolist()\n",
    "\n",
    "def get_df_concept(embedding_function):\n",
    "    df_concept = pnd.read_csv(\n",
    "        \"/home/knub/Repositories/master-thesis/data/concept-categorization/battig_concept-categorization.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        header=None)\n",
    "    df_concept.columns = [\"word\", \"concept\"]\n",
    "    df_concept[\"embeddings\"] = df_concept[\"word\"].apply(embedding_function)\n",
    "    return df_concept\n",
    "\n",
    "df_we_concept = get_df_concept(get_embedding_from_word_embedding)\n",
    "df_tm_concept = get_df_concept(get_embedding_from_topics)\n",
    "df_tm_concept.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-15T13:55:18.161904",
     "start_time": "2016-07-15T13:55:18.145182"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df_tm_concept.ix[0,\"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-15T13:55:18.935681",
     "start_time": "2016-07-15T13:55:18.912877"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# http://stats.stackexchange.com/questions/95731/how-to-calculate-purity\n",
    "def single_cluster_purity(df_param):\n",
    "    return df_param[\"concept\"].value_counts().max()\n",
    "\n",
    "def calculate_purity(df_param):\n",
    "    purity = float(sum([single_cluster_purity(df_cluster_group)\n",
    "                        for _, df_cluster_group\n",
    "                        in df_param.groupby(\"cluster_id\")])) / len(df_param)\n",
    "    return purity\n",
    "\n",
    "\n",
    "def evaluate_clustering_algorithm(df_param, clustering):\n",
    "    X = np.array(df_param[\"embeddings\"].tolist())\n",
    "    X_sim = metrics.pairwise.pairwise_distances(X, metric=\"cosine\")\n",
    "    # sim or not sim? PCA or not PCA?\n",
    "    clusters = clustering.fit_predict(pca(X_sim, 10))\n",
    "    df_param[\"cluster_id\"] = clusters\n",
    "    return calculate_purity(df_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-15T13:55:21.129716",
     "start_time": "2016-07-15T13:55:20.420020"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for df_concept in [df_we_concept, df_tm_concept]:\n",
    "    print \"-\" * 100\n",
    "    for clustering in [KMeans(n_clusters=10, init=\"k-means++\", n_jobs=1),\n",
    "                       AgglomerativeClustering(n_clusters=10, linkage=\"ward\"),\n",
    "                       AgglomerativeClustering(n_clusters=10, linkage=\"complete\"),\n",
    "                       AgglomerativeClustering(n_clusters=10, linkage=\"average\"),\n",
    "                       AffinityPropagation(damping=0.5),\n",
    "                       AffinityPropagation(damping=0.6),\n",
    "                       AffinityPropagation(damping=0.7),\n",
    "                       AffinityPropagation(damping=0.8),\n",
    "                       AffinityPropagation(damping=0.9),\n",
    "                   SpectralClustering(n_clusters=3)]:\n",
    "        print clustering.__class__.__name__\n",
    "        print evaluate_clustering_algorithm(df_concept, clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Word Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-15T14:12:11.380713",
     "start_time": "2016-07-15T14:12:11.110894"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def word_similarity(f):\n",
    "    try:        \n",
    "        df_sim = pnd.read_csv(MODEL + f, sep=\"\\t\")\n",
    "        df_sim[\"embedding-sim\"] = df_sim[[\"word1\", \"word2\"]].apply(\n",
    "            lambda x: model.get_similarity(x[\"word1\"], x[\"word2\"], vectors), axis=1)\n",
    "        topic_sim_column = df_sim.columns[3]\n",
    "        \n",
    "        topic_corr     = df_sim[[\"human-sim\", topic_sim_column]].corr(\"spearman\").ix[0,1]\n",
    "        embedding_corr = df_sim[[\"human-sim\", \"embedding-sim\"]].corr(\"spearman\").ix[0, 1]\n",
    "        \n",
    "        return pnd.DataFrame([[topic_corr, embedding_corr]],\n",
    "                             columns=[\"topic_corr\", \"embedding_corr\"],\n",
    "                             index=[f])\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "df_tmp = pnd.concat([word_similarity(\".wordsim353-all-bhattacharyya\"),\n",
    "            word_similarity(\".wordsim353-all-hellinger\"),\n",
    "            word_similarity(\".wordsim353-all-jensen-shannon\"),\n",
    "            word_similarity(\".wordsim353-all-sum\"),\n",
    "            word_similarity(\".wordsim353-rel-bhattacharyya\"),\n",
    "            word_similarity(\".wordsim353-rel-hellinger\"),\n",
    "            word_similarity(\".wordsim353-rel-jensen-shannon\"),\n",
    "            word_similarity(\".wordsim353-rel-sum\"),\n",
    "            word_similarity(\".wordsim353-sim-bhattacharyya\"),\n",
    "            word_similarity(\".wordsim353-sim-hellinger\"),\n",
    "            word_similarity(\".wordsim353-sim-jensen-shannon\"),\n",
    "            word_similarity(\".wordsim353-sim-sum\")])\n",
    "df_tmp.sort_values(by=\"topic_corr\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
