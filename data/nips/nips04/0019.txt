Perturbing Hebbian Rules 
Peter Dayan 
CNL, The Salk Institute 
PO Box 85800 
San Diego CA 92186-5800, USA 
dayanhelmholtz. sdsc. edu 
Geoffrey Goodhill 
COGS 
University of Sussex, Falmer 
Brighton BN1 9QN, UK 
geogcogs. susx. ac. uk 
Abstract 
Recently Linsker [2] and MacKay and Miller [3, 4] have analysed Hebbian 
correlational rules for synaptic development in the visual system, and 
Miller [5, 8] has studied such rules in the case of two populations of fibres 
(particularly two eyes). Miller's analysis has so far assumed that each of 
the two populations has exactly the same correlational structure. Relaxing 
this constraint by considering the effects of small perturbative correlations 
within and between eyes permits study of the stability of the solutions. 
We predict circumstances in which qualitative changes are seen, including 
the production of binocularly rather than monocularly driven units. 
1 INTRODUCTION 
Linsker [2] studied how a Hebbian correlational rule could predict the development 
of certain receptive field structures seen in the visual system. MacKay and Miller 
[3, 4] pointed out that the form of this learning rule meant that it could be analysed 
in terms of the eigenvectors of the matrix of time-averaged presynaptic correlations. 
Miller [5, 8, 7] independently studied a similar correlational rule for the case of two 
eyes (or more generally two populations), explaining how cells develop in V1 
that are ultimately responsive to only one eye, despite starting off as responsive 
to both. This process is again driven by the eigenvectors and eigenvalues of 
the developmental equation, and Miller [7] relates Linsker's model to the two 
population case. 
Miller's analysis so far assumes that the correlations of activity within each popula- 
tion are identical. This special case simplifies the analysis enabling the projections 
from the two eyes to be separated out into sum and difference variables. In general, 
19 
20 Dayan and Goodhill 
one would expect the correlations to differ slightly, and for correlations between the 
eyes to be not exactly zero. We analyse how such perturbations affect the eigenvec- 
tors and eigenvalues of the developmental equation, and are able to explain some 
of the results found empirically by Miller [6]. 
Further details on this analysis and on the relationship between Hebbian and 
non-Hebbian models of the development of ocular dominance and orientation 
selectivity can be found in Goodhill (1991). 
2 THE EQUATION 
MacKay and Miller [3, 4] study Linsker's [2] developmental equation in the form: 
 = (Q + k2I)w + 
where w = [wi], i  [1, rt] are the weights from the units in one layer Te. to a 
particular unit in the next layer ,_q, Q is the covariance matrix of the activities of the 
units in layer Te., J is the matrix Jii = 1, ¾ i, j, and ,t is the 'DC' vector rti = l, ¾ i. 
The equivalent for two populations of cells is: 
02 = Qc+kJ Q+kJ 
w2 + k 
where Q gives the covariance between cells within the first population, Q2 gives 
that between cells within the second, and Qc (assumed symmetric) gives the covari- 
ance between cells in the two populations. Define Q, as this full, two population, 
development matrix. 
Miller studies the case in which Q = Q2 = Q and Qc is generally zero or slightly 
negative. Then the development of w - w2 (which Miller calls S v) and w + w2 
(S s) separate; for Qc = 0, these go like: 
fiS v ris s 
fit = QSO and fit = (Q +2k2J)ss + 2kt. 
and, up to various forms of normalisation and/or weight saturation, the patterns 
of dominance between the two populations are determined by the initial value 
and the fastest growing components of S ø . If upper and lower weight saturation 
limits are reached at roughly the same time (Berns, personal communication), the 
conventional assumption that the fastest growing eigenvectors of S ø dominate the 
terminal state is borne out. 
The starting condition Miller adopts has w - w2 = e'a and w + w2 = b, where 
e' is small, and a and b are O(1). Weights are constrained to be positive, and 
saturate at some upper limit. Also, additive normalisation is applied throughout 
development, which affects the growth of the S s (but not the S v) modes. As 
discussed by MacKay and Miller [3, 4], this is approximately accommodated in the 
k2J component. 
Mackay and Miller analyse the eigendecomposition of Q + kJ for general and 
radially symmetric covariance matrices Q and all values of k2. It turns out that the 
eigendecomposition of Q. for the case Q = Q = Q and Qc = 0 (that studied by 
Miller) is given in table form by: 
Perturbing Hebbian Rules 21 
E-vector E-value Conditions 
(xi,xi) Xi Qxi = Xixi n.xi = 0 
(Xi,--Xi) i Qxi "- XiXi 11.Xi -- 0 
(!Ji,-!Ji) gi Q!Ji -- ViiIt n.!Ji  0 
(zi,zi) 'vi (Q + 2k2J)zi ='vizt n.zi  0 
Figure I shows the matrix and the two key (9,-9) and (x,-x) eigenvectors. 
The details of the decomposition of Q. in this table are slightly obscured by de- 
generacy in the eigendecomposition of Q + k2J. Also, for clarity4 we write (xi, xi) 
for (xi, xi) r. A consequence of the first two rows in the table is that (rlxi, 0xi) is an 
eigenvector for any rl and 0; this becomes important later. 
That the development of S v and $s separates can be seen in the (u, u) and (u, -u) 
forms of the eigenvectors. In Miller's terms the onset of dominance of one of the 
two populations is seen in the (u, -u) eigenvectors - dominance requires that Vi 
for the eigenvector whose elements are all of the same sign (one such exists for 
Miller's Q) is larger than the Vi and the Xi for all the other such eigenvectors. In 
particular, on pages 296-300 of [6], he shows various cases for which this does and 
one in which it does not happen. To understand how this comes about, we can 
treat the latter as a perturbed version of the former. 
3 PERTURBATIONS 
Consider the case in which there are small correlations between the projections 
and/or small differences between the correlations within each projection. For 
instance, one of Miller's examples indicates that small within-eye anti-correlations 
can prevent the onset of dominance. This can be perturbatively analysed by setting 
Q1 = Q + eel, Q2 = Q + eE2 and Qc = eEc. Call the resulting matrix Q.. 
Two questions are relevant. Firstly, are the eigenvectors stable to this perturbation, 
ie are there vectors cl and a2 such that (ul + eal, u2 + ca2) is an eigenvector of 
Q. if (ul, u2) is an eigenvector of Q. with eigenvalue dp? Secondly, how do the 
eigenvalues change? 
One way to calculate this is to consider the equation the perturbed eigenvector 
must satisfy:  
and look for conditions on ul and u2 and the values of oh, a2 and  by equating 
the O(e) terms. We now consider a specific example. Using the notation of the 
table above, (9i + eal, -9i + ca2) is an eigenvector with eigenvalue Vi + ei if 
(Q-viI) ch+k2J(ch+ct2) = -(E1-Ec-iI)!Ji, and 
(Q-viI) a2+k2J(a,+a2) = -(Ec-E2+q)iI)tli. 
Subtracting these two implies that 
(Q - Vii)(tll - a2) = -(E, - 2Ec + E2 - 2qiI) Ut. 
This is a standard method for such linear systems, eg in quantum mechanics. 
22 Dayan and Goodhill 
However, ti[ (Q - ItI) = 0, since Q is symmetric and tit is an eigenvector with 
eigenvalue It, so multiplying on the left by tit -r, we require that 
2kbttirtit = tiir (E, - 2Ec + E2) tit 
which sets the value of t. Therefore (tit, -tit) is stable in the required manner. 
Similarly (zt, zt) is stable too, with an equivalent perturbation to its eigenvalue. 
However the pair (xt, xt) and (xt,-xt) are not stable - the degeneracy from their 
having the same eigenvalue is broken, and two specific eigenvectors, (octxt, ftXt) 
and (- ftXt, OCtXt) are stable, for particular values oct and ft. This means that to first 
order, S U and S s no longer separate, and the full, two-population, matrix must be 
solved. 
To model Miller's results, call Q.. the special case of Q. for which E = E2 = E 
and Ec = 0. Also, assume that the xt, tit and zt are normalised, let e (u) = urEu, 
etc, and define'¾(u) = (e(u)- e2(u))/2ec(U), for ec(U)  0, and '¾t = '¾(xt). Then 
we have 
/oct = -Yt + V/1 + Yt 2 
and the eigenvalues are: 
Eigenvalue for case: 
E-vector Q, Q,. Q, 
(octXt, fiX:i) )kt )kt + ee(Xt) ;kt + e[e(xt) + e2(xt) + Et]/2 
(-ftXt, octXi) ;kt ;ki + ee(xt) ;kt - e[e(xt) + e2(xt) + Et]/2 
(tit,-tit) t Ixt + ee (tit) Ixt + e[el(tit) + e2(tit) - 2ec(tit)]/2 
(zt, zt) 'i 't + ee(zt) 't + e[e(zt) + e2(zt) + 2ec(zt)]/2 
(1) 
where Et = v/[e (xt) - ½2(x0] 2 + 4ec(Xt) 2. For the case Miller treats, since E = E2, 
the degeneracy in the original solution is preserved, ie the perturbed versions of 
(xt, xt) and (xt,-xt) have the same eigenvalues. Therefore the S v and S s modes 
still separate. 
This perturbed eigendecomposition suffices to show how small additional correla- 
tions affect the solutions. We will give three examples. The case mentioned above 
on page 299 of [6], shows how small same-eye anti-correlations within the radius 
of the arbor function cause a particular (tit,-tit) eigenvector (i.e. one for which 
all the components of tit have the same sign) to change from growing faster than 
a (xt,-xt) (for which some components of xi are positive and some negative to 
ensure that n.xt = 0) to growing slower than it, converting a monocular solution 
to a binocular one. 
In our terms, this is the Q,,m case, with E a negative matrix. Given the conditions 
on signs of their components, e(tit) is more negative than e(xt), and so the 
eigenvalue for the perturbed (tit,-tit) would be expected to decrease more than 
that for the perturbed (xt,-xt). This is exactly what is found. Different binocular 
eigensolutions are affected by different amounts, and it is typically a delicate issue 
as to which will ultimately prevail. Figure 2 shows a sample perturbed matrix for 
which dominance will not develop. If the change in the correlations is large ((9(1)), 
then the eigenfunctions can change shape (eg ls becomes 2s in the notation of [4]). 
We do not address this here, since we are considering only changes of CO(e). 
Perturbing Hebbian Rules 23 
1 
o 
0.5 
0.25 
o 
2o 
4o 
2o 
6o 
o 
60 
Figure 1: Unperturbed two-eye correlation matrix and (U,-U), (x,-x) eigenvec- 
tots. Eigenvalues are 7.1 and 6.4 respectively. 
O. l)O '  
0.4 ''* 
0.2 60 
40 
2O 
2O 
6O 
0 
Figure 2: Same-eye anti-correlation matrix and eigenvectors. (U, -U), (x, -x) eigen- 
values are 4.8 and 5.4 respectivel and so the order has swapped. 
24 Dayan and Goodhill 
Positive opposite-eye correlations can have exactly the same effect. This time ec(!t) 
is greater than ec(xt), and so, again, the eigenvalue for the perturbed (gt,-9t) 
would be expected to decrease more than that for the perturbed (xt, -xt). Figure 3 
shows an example which is infelicitous for dominance. 
The third case is for general perturbations in Q,. Now the mere signs of the 
components of the eigenvectors are not enough to predict which will be affected 
more. Figure 4 gives an example for which ocular dominance will still occur. Note 
that the (xt, -xi) eigenvector is no longer stable, and has been replaced by one of 
the form (xt, fSt,xt). 
If general perturbations of the same order of magnitude as the difference between 
w and w2 (iee' ___ e) are applied, the oct and fit terms complicate Miller's S D 
analysis to first order. Let w(0) - w2(0) = ect and apply Q, as an iteration matrix. 
w (rt) -w2(rt), the difference between the projections after rt iterations has no (9(1) 
component, but two sets of O(e) components; {2t? (a.t) t}, and 
{ + e(T + (octxt.w(0) + (oct - ft)xt - 
;1'[1 + (Tt - Et)/2;kt]" (octxt.w2(0) - fSixi.wl (0))(oct + 15t)xi } 
where Tt = el (xt) + e2(xt). Collecting the terms in this expression, and using 
equation 1, we derive 
where b = w(0) + w2(0). The second part of this expression depends on 
and is substantial because w(0) + w2(0) is O(1). Such a term does not appear 
in the unperturbed system, and can bias the competition between the 9 and the 
xt eigenvectors, in particular towards the binocular solutions. Again, its precise 
effects will be sensitive to the unperturbed eigenvalues. 
4 CONCLUSIONS 
Perturbation analysis applied to simple Hebbian correlational learning rules reveals 
the following: 
ß Introducing small anti-correlations within each eye causes a tendency toward 
binocularity. This agrees with the results of Miller. 
ß Introducing small positive correlations between the eyes (as will inevitably 
occur once they experience a natural environment) has the same effect. 
ß The overall eigensolution is not stable to small perturbations that make the 
correlational structure of the two eyes unequal. This also produces interesting 
effects on the growth rates of the eigenvectors concerned, given the initial 
conditions of approximately equivalent projections from both eyes. 
Acknowledgements 
We are very grateful to Ken Miller for helpful discussions, and to Christopher 
Longuet-Higgins for pointing us in the direction of perturbation analysis. Support 
Perturbing Hebbian Rules 25 
0.75 80 
0.5 
0.25 SO 
0 
40 2O 
6O 
:80 
Figure 3: Opposite-eye positive correlation matrix and eigenvectors. Eigenvalues 
of (U, -U), (x,-x) are 4.8 and 5.4, so ocular dominance is again inhibited. 
80 
0. 
80 
Figure 4: The effect of random perturbations to the matrix. Although the order is 
restored (eigenvalues are 7.1 and 6.4), note the (0cx, fix) eigenvector. 
26 Dayan and Goodhill 
was from the SERC and a Nuffield Foundation Science travel grant to GG. GG 
is grateful to David Willshaw and the Centre for Cognitive Science for their hos- 
pitality. GG's current address is The Centre for Cognitive Science, University of 
Edinburgh, 2 Buccleuch Place, Edinburgh EH8 9LW, Scotland, and correspondence 
should be directed to him there. 
References 
[1] Goodhill, GJ (1991). Correlations, Competition and Optimality: Modelling the De- 
velopment of Topography and Ocular Dominance. PhD Thesis, Sussex University. 
[2] Linsker, R (1986). From basic network principles to neural architecture (series). 
Proc. Nat. Acad. Sci., USA, 83, pp 7508-7512, 8390-8394, 8779-8783. 
[3] MacKay, DJC & Miller, KD (1990). Analysis of Linsker's simulations of Heb- 
bian rules. Neural Computation, 2, pp 169-182. 
[4] MacKay, DJC & Miller, KD (1990). Analysis of Linsker's application of Hebbian 
rules to linear networks. Network, 1, pp 257-297. 
[5] Miller, KD (1989). Correlation-based Mechanisms in Visual Cortex: Theoretical and 
Empirical Studies. PhD Thesis, Stanford University Medical School. 
[6] Miller, KD (1990). Correlation-based mechanisms of neural development. In 
MA Gluck & DE Rumelhart, editors, Neuroscience and Connectionist Theory. 
Hillsborough, NJ: Lawrence Erlbaum. 
[7] Miller, KD (1990). Derivation of linear Hebbian equations from a nonlinear 
Hebbian model of synaptic plasticity. Neural Computation, 2, pp 321-333. 
[8] Miller, KD, Keller, JB & Stryker, MP (1989). Ocular dominance column devel- 
opment: Analysis and simulation. Science, 245, pp 605-615. 
