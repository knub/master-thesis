Oscillatory Neural Fields for 
Globally Optimal Path Planning 
Michael Letomort 
Dept. of Electrical Engineering 
University of Notre Dame 
Notre Dame, Indiana 46556 
Abstract 
A neural network solution is proposed for solving path planning problems 
faced by mobile robots. The proposed network is a two-dimensional sheet 
of neurons forming a distributed representation of the robot's workspace. 
Lateral interconnections between neurons are "cooperative", so that the 
network exhibits oscillatory behaviour. These oscillations are used to gen- 
erate solutions of Bellman's dynamic programming equation in the context 
of path planning. Simulation experiments imply that these networks locate 
global optimal paths even in the presence of substantial levels of circuit 
noise. 
1 Dynamic Programming and Path Planning 
Consider a 2-DOF robot moving about in a 2-dimensional world. A robot's location 
is denoted by the real vector, p. The collection of all locations forms a set called the 
workspace. An admissible point in the workspace is any location which the robot 
may occupy. The set of all admissible points is called the free workspace. The 
free workspace's complement represents a collection of obstacles. The robot moves 
through the workspace along a path which is denoted by the parameterized curve, 
p(t). An admissible path is one which lies wholly in the robot's free workspace. 
Assume that there is an initial robot position, p0, and a desired final position, 
The robot path planning problem is to find an admissible path with p0 and p j, as 
endpoints such that some "optimality" criterion is satisfied. 
The path planning problem may be stated more precisely from an optimal control 
539 
540 Lemmon 
theorist's viewpoint. Treat the robot as a dynamic system which is characterized 
by a state vector, p, and a control vector, u. For the highest levels in a control 
hierarchy, it can be assumed that the robot's dynamics are modeled by the dif- 
ferential equation, ) = u. This equation says that the state velocity equals the 
applied control. To define what is meant by "optimal", a performance functional is 
introduced. 
J(u) = lip(Q) - prl] 2 + c(p) utudt (1) 
where Ilxll is the norm of vector x and where the functional c(p) is unity if p lies 
in the free workspace and is infinite otherwise. This weighting functional is used 
to insure that the control does not take the robot into obstacles. Equation l's 
optimality criterion minimizes the robot's control effort while penalizing controls 
which do not satisfy the terminal constraints. 
With the preceding definitions, the optimal path planning problem states that for 
some final time, Q, find the control u(t) which minimizes the performance functional 
J(u). One very powerful method for tackling this minimization problem is to use 
dynamic programming (Bryson, 1975). According to dynamic programming, the 
optimal control, Uopt, is obtained from the gradient of an "optimal return function", 
jO(p). In other words, uopt = X7J ø. The optimal return functional satisfies the 
Hamilton-Jacobi-Bellman (HJB) equation. For the dynamic optimization problem 
given above, the HJB equation is easily shown to be 
OJ ø ( -¬(X7Jø)t(zJ ø) c(p) = 1 (2) 
= 0 c(p) = 
This is a first order nonlinear partial differential equation (PDE) with terminal 
(boundary) condition, Jø(tf) = liP(Q)- P'I?. Once equation 2 has been solved 
for the jo, then the optimal "path" is determined by following the gradient of jo. 
Solutions to equation 2 must generally be obtained numerically. One solution ap- 
proach numerically integrates a full discretization of equation 2 backwards in time 
using the terminal condition, jo(Q), as the starting point. The proposed numerical 
solution is attempting to find characteristic trajectories of the nonlinear first-order 
PDE. The PDE nonlinearities, however, only insure that these characteristics exist 
locally (i.e., in an open neighborhood about the terminal condition). The resulting 
numerical solutions are, therefore, only valid in a "local" sense. This is reflected in 
the fact that truncation errors introduced by the discretization process will even- 
tually result in numerical solutions violating the underlying principle of optimality 
embodied by the HJB equation. 
In solving path planning problems, local solutions based on the numerical integra- 
tion of equation 2 are not acceptable due to the "local" nature of the resulting 
solutions. Global solutions are required and these may be obtained by solving an 
associated variational problem (Benton, 1977). Assume that the optimal return 
function at time ty is known on a closed set B. The variational solution for equa- 
tion 2 states that the optimal return at time t < ty at a point p in the neighborhood 
of the boundary set B will be given by 
Jø(p,t): min {Jø(y, tf)+ [[p- Yl[a} 
yes (Q -t) 
(3) 
Oscillatory Neural Fields for Globally Optimal Path Planning 541 
where Ilpll denotes the L2 norm of vector p. Equation 3 is easily generalized to 
other vector norms and only applies in regions where c(p) = 1 (i.e. the robot's free 
workspace). For obstacles, Jø(p,t) = Jø(p, tf) for all t < tf. In other words, the 
optimal return is unchanged in obstacles. 
2 Oscillatory Neural Fields 
The proposed neural network consists of MN neurons arranged as a 2-d sheet 
called a "neural field". The neurons are put in a one-to-one correspondence with 
the ordered pairs, (i,j) where i = 1,...,N and j = 1,...,M. The ordered pair 
(i,j) will sometimes be called the (i,j)th neuron's "label". Associated with the 
(i, j)th neuron is a set of neuron labels denoted by Ni,d. The neurons' whose labels 
lie in Ni,/ are called the "neighbors" of the (i, j)th neuron. 
The (i,j)th neuron is characterized by two states. The short term activity (STA) 
state, xi,j, is a scalar representing the neuron's activity in response to the currently 
applied stimulus. The long term activity (LTA) state, wi,j, is a scalar representing 
the neuron's "average" activity in response to recently applied stimuli. Each neuron 
produces an output, f(xi,j), which is a unit step function of the STA state. (i.e., 
fix) = 1 ifx > 0 and f(x) = 0 ifx _< 0). A neuron will be called "active" or 
"inactive" if its output is unity or zero, respectively. 
Each neuron is also characterized by a set of constants. These constants are either 
externally applied inputs or internal parameters. They are the disturbance Yi,j, 
the rate constant Xi,j, and the position vector Pi,j. The position vector is a 2-d 
vector mapping the neuron onto the robot's workspace. The rate constant models 
the STA state's underlying dynamic time constant. The rate constant is used to 
encode whether or not a neuron maps onto an obstacle in the robot's workspace. 
The external disturbance is used to initiate the network's search for the optimal 
path. 
The evolution of the STA and LTA states is controlled by the state equations. These 
equations are assumed to change in a synchronous fashion. The STA state equation 
is 
Y Dktf(xk,t)) (4) 
where the summation is over all neurons contained within the neighborhood, Ni,i, 
of the (i,j)th neuron. The function G(x) is zero if x < 0 and is x if x >_ 0. 
This function is used to prevent the neuron's activity level from falling below zero. 
Dkt are network parameters controlling the strength of lateral interactions between 
neurons. The LTA state equation is 
= w,,5 + 
Equation 5 means that the LTA state is incremented by one every time the (i, j)th 
neuron's output changes. 
Specific choices for the interconnection weights result in oscillatory behaviour. The 
specific network under consideration is a cooperative field where D! = i if (k, l)  
542 Lemmon 
(i,j) and Dtt = -A < 0 if (k,l) = (i,j). Without loss of generality it will also be 
assumed that the external disturbances are bounded between zero and one. It is also 
assumed that the rate constants, Ai,j are either zero or unity. In the path planning 
application, rate constants will be used to encode whether or not a given neuron 
represents an obstacle or a point in the free-workspace. Consequently, any neuron 
where Ai,j = 0 will be called an "obstacle" neuron and any neuron where Xi,j = 1 
will be called a "free-space" neuron. Under these assumptions, it has been shown 
(Lemmon, 1991a) that once a free-space neuron turns active it will be oscillating 
with a period of 2 provided it has at least one free-space neuron as a neighbor. 
3 Path Planning and Neural Fields 
The oscillatory neural field introduced above can be used to generate solutions of 
the Bellman iteration (Eq. 3) with respect to the supremum norm. Assume that all 
neuron STA and LTA states are zero at time 0. Assume that the position vectors 
form a regular grid of points, Pi,i = (iA, jA) t where A is a constant controlling the 
grid's size. Assume that all external disturbances but one are zero. In other words, 
for a specific neuron with label (i,j), yt,t = 1 if (k,l) = (i,j) and is zero otherwise. 
Also assume a neighborhood structure where Ni,j consist of the (i, j)th neuron and 
its eight nearest neighbors, Ni,j = {(i+ k,j+ l);k =-1,0, 1;/= -1,0, 1}. With 
these assumptions it has been shown (Lemmon, 1991a) that the LTA state for the 
(i, j)th neuron at time n will be given by G(n - pit) where pit is the length of the 
shortest path from pt,I and Pi,i with respect to the supremum norm. 
This fact can be seen quite clearly by examining the LTA state's dynamics in a 
small closed neighborhood about the (k,/)th neuron. First note that the LTA state 
equation simply increments the LTA state by one every time the neuron's STA state 
toggles its output. Since a neuron oscillates after it has been initially activated, the 
LTA state, will represent the time at which the neuron was first activated. This 
time, in turn, will simply be the "length" of the shortest path from the site of 
the initial distrubance. In particular, consider the neighborhood set for the (k,/)th 
neuron and let's assume that the (k,/)th neuron has not yet been activated. If the 
neighbor has been activated, with an LTA state of a given value, then we see that 
the (k,/)th neuron will be activated on the next cycle and we have 
wt,t = max win,r, - (6) 
This is simply a dual form of the Bellman iteration shown in equation 3. In other 
words, over the free-space neurons, we can conclude that the network is solving the 
Bellman equation with respect to the supremum norm. 
In light of the preceding discussion, the use of cooperative neural fields for path 
planning is straightforward. First apply a disturbance at the neuron mapping onto 
the desired terminal position, Pt and allow the field to generate STA oscillations. 
When the neuron mapping onto the robot's current position is activated, stop the 
oscillatory behaviour. The resulting LTA state distribution for the (i, j)th neuron 
equals the negative of the minimum distance (with respect to the sup norm) from 
that neuron to the initial disturbance. The optimal path is then generated by a 
sequence of controls which ascends the gradient of the LTA state distribution. 
Oscillatory Neural Fields for Globally Optimal Path Planning 543 
fig 1. STA activity waves 
fig 2. LTA distribution 
Several simulations of the cooperative neural path planner have been implemented. 
The most complex case studied by these simulations assumed an array of 100 by 100 
neurons. Several obstacles of irregular shape and size were randomly distributed 
over the workspace. An initial disturbance was introduced at the desired terminal 
location and STA oscillations were observed. A snapshot of the neuronal outputs 
is shown in figure 1. This figure clearly shows wavefronts of neuronal activity prop- 
agating away from the initial disturbance (neuron (70,10) in the upper right hand 
corner of figure 1). The "activity" waves propagate around obstacles without any 
reflections. When the activity waves reach the neuron mapping onto the robot's 
current position, the STA oscillations were turned off. The LTA distribution re- 
sulting from this particular simulation run is shown in figure 2. In this figure, light 
regions denote areas of large LTA state and dark regions denote areas of small LTA 
state. 
The generation of the optimal path can be computed as the robot is moving towards 
its goal. Let the robot's current position be the (i,j)th neuron's position vector. 
The robot will then generate a control which takes it to the position associated with 
one of the (i, j)th neuron's neighbors. In particular, the control is chosen so that 
the robot moves to the neuron whose LTA state is largest in the neighborhood set, 
Nid. In other words, the next position vector to be chosen is pk,I such that its LTA 
state is 
wt,,I = max wa,y (7) 
Because of the LTA distribution 's optimality property, this local control strategy is 
guaranteed to generate the optimal path (with respect to the sup norm) connecting 
the robot to its desired terminal position. It should be noted that the selection of 
the control can also be done with an analog neural network. In this case, the LTA 
544 Lcmmon 
states of neurons in the neighborhood set, Ni,j are used as inputs to a competitively 
inhibited neural net. The competitive interactions in this network will always select 
the direction with the largest LTA state. 
Since neuronal dynamics are analog in nature, it is important to consider the impact 
of noise on the implementation. Analog systems will generally exhibit noise levels 
with effective dynamic ranges being at most 6 to 8 bits. Noise can enter the network 
in several ways. The LTA state equation can have a noise term (LTA noise), so that 
the LTA distribution may deviate from the optimal distribution. In our experiments, 
we assumed that LTA noise was additive and white. Noise may also enter in the 
selection of the robot's controls (selection noise). In this case, the robot's next 
position is the position vector, Pk,I such that wk,I = max(,y)EN,s(w,y + V,y) 
where Vr,y is an i.i.d array of stochastic processes. Simulation results reported 
below assume that the noise processes, Vr,y, are positive and uniformly distributed 
i.i.d. processes. The introduction of noise places constraints on the "quality" of 
individual neurons, where quality is measured by the neuron's effective dynamic 
range. Two sets of simulation experiments have been conducted to assess the neural 
field's dynamic range requirements. In the following simulations, dynamic range is 
defined by the equation -log 2 ]vm], where ]vml is the maximum value the noise 
process can take. The unit for this measure of dynamic range is "bits". 
The first set of simulation experiments selected robotic controls in a noisy fashion. 
Figure 3 shows the paths generated by a simulation run where the signal to noise 
ratio was i (0 bits). The results indicate that the impact of "selection" noise is 
to "confuse" the robot so it takes longer to find the desired terminal point. The 
path shown in figures 3 represents a random walk about the true optimal path. 
The important thing to note about this example is that the system is capable of 
tolerating extremely large amounts of "selection" noise. 
The second set of simulation experiments introduced LTA noise. These noise ex- 
periments had a detrimental effect on the robot's path planning abilities in that 
several spurious extremals were generated in the LTA distribution. The result of 
the spurious extremals is to fool the robot into thinking it has reached its terminal 
destination when in fact it has not. As noise levels increase, the number of spurious 
states increase. Figure 4, shows how this increase varies with the neuron's effective 
dynamic range. The surprising thing about this result is that for neurons with as 
little as 3 bits of effective dynamic range the LTA distribution is free of spurious 
maxima. Even with less than 3 bits of dynamic range, the performance degradation 
is not catastrophic. LTA noise may cause the robot to stop early; but upon stop- 
ping the robot is closer to the desired terminal state. Therefore, the path planning 
module can be easily run again and because the robot is closer to its goal there will 
be a greater probability of success in the second trial. 
4 Extensions and Conclusions 
This paper reported on the use of oscillatory neural networks to solve path plan- 
ning problems. It was shown that the proposed neural field can compute dynamic 
programming solutions to path planning problems with respect to the supremeum 
norm. Simulation experiments showed that this approach exhibited low sensitivity 
Oscillatory Neural Fields for Globally Optimal Path Planning 545 
fig 3. Selected Path 
I I I I 
Dynamic Range (bits)- 
1 2 3 4 
fig 4. Dynamic Range 
to noise, thereby supporting the feasibility of analog VLSI implementations. 
The work reported here is related to resistive grid approaches for solving optimiza- 
tion problems (Chua, 1984). Resistive grid approaches may be viewed as "passive" 
relaxation methods, while the oscillatory neural field is an "active" approach. The 
priinary virtue of the "active" approach lies in the network's potential to control the 
optimization criterion by selecting the interconnections and rate constants. In this 
paper and (Lemmon, 1991a), lateral interconnections were chosen to induce STA 
state oscillations and this choice yields a network which solves the Bellman equation 
with respect to the supremum norm. A slight modification of this model is currently 
under investigation in which the neuron's dynamics directly realize the iteration of 
equation 6 with respect to more general path metrics. This analog network is based 
on an SIMD approach originally proposed in (Lemmon, 1991). Results for this field 
are shown in figures 5 and 6. These figures show paths determined by networks 
utilizing different path metrics. In figure 5, the network penalizes movement in all 
directions equally. In figure 6, there is a strong penalty for horizontal or vertical 
movements. As a result of these penalties (which are implemented directly in the 
interconnection constants Dkl), the two networks' "optimal" paths are different. 
The path in figure 6 shows a clear preference for making diagonal rather than verti- 
cal or horizontal moves. These results clearly demonstrate the ability of an "active" 
neural field to solve path planning problems with respect to general path metrics. 
These different path metrics, of course, represent constraints on the system's path 
planning capabilities and as a result suggest that "active" networks may provide a 
systematic way of incorporating holonomic and nonholonomic constraints into the 
path planning process. 
A final comment must be made on the apparent complexity of this approach. 
546 Lcmmon 
fig 5. No Direction Favored fig 6. Diagonal Direction Favored 
Clearly, if this method is to be of practical significance, it must be extended beyond 
the 2-DOF problem to arbitrary task domains. This extension, however, is nontriv- 
ial due to the "curse of dimensionality" experienced by straightforward applications 
of dynamic programming. An important area of future research therefore addresses 
the decomposition of real-world tasks into smaller subtasks which are amenable to 
the solution methodology proposed in this paper. 
Acknowledgements 
I would like to acknowledge the partial financial support of the National Science 
Foundation, grant number NSF-IRI-91-09298. 
References 
S.H. Benton Jr., (1977) The Hamilton-Jacobi equation: A Global Approach. Aca- 
demic Press. 
A.E. Bryson and Y.C. Ho, (1975) Applied Optimal Control, Hemisphere Publishing. 
Washington D.C. 
L.O. Chua and G.N. Lin, (1984) Nonlinear programming without computation, 
IEEE Trans. Circuits Syst., CAS-31:182-188 
M.D. Lemmon, (1991) Real time optimal path planning using a distributed comput- 
ing paradigm, Proceedings of the Americal Control Conference, Boston, MA, June 
1991. 
M.D. Lemmon, (1991a) 2-Degree-of-Freedom Robot Path Planning using Coopera- 
tive Neural Fields. Neural Computation 3(3):350-362. 
