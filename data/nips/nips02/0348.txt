348 Farotimi, Dembo and Kailath 
Neural Network Weight Matrix Synthesis 
Optimal Control Techniques 
Using 
O. Farotimi 
A. Dembo 
Information Systems Lab. 
Electrical Engineering Dept. 
Stanford University, 
Stanford, CA 94305 
T. Kailath 
ABSTRACT 
Given a set of input-output training samples, we describe a proce- 
dure for determining the time sequence of weights for a dynamic 
neural network to model an arbitrary input-output process. We 
formulate the input-output mapping problem as an optimal con- 
trol problem, defining a performance index to be minimized as a 
function of time-varying weights. We solve the resulting nonlin- 
ear two-point-boundary-value problem, and this yields the training 
rule. For the performance index chosen, this rule turns out to be a 
continuous time generalization of the outer product rule earlier sug- 
gested heuristically by Hopfield for designing associative memories. 
Learning curves for the new technique are presented. 
I INTRODUCTION 
Suppose that we desire to model as best as possible some unknown map qb ß L/ --, 
12, where H, 12 C_ '. One way we might go about doing this is to collect as many 
input-output samples {(9i,, o,t) ' qb(i,) = 9o, t } as possible and "find" some func- 
tion f' H --, 12 such that a suitable distance metric d(f(z(t)), qb(z(t)))lzE(t),,,:qb(t,,)=t)o.,} 
is minimized. 
In the foregoing, we assume a system of ordinary differential equations motivated by 
dynamic neural network structures[i] [2]. In particular we set up an n-dimensional 
Neural Network Weight Matrix Synthesis 349 
neural network; call it N'. Our goal is to synthesize a possibly time varying weight 
matrix for A/' such that for initial conditions z(t0), the input-output transformation, 
or flow f: z(t0) -- f(z(tl) ) associated with A/' approximates closely the desired 
map b. 
For the purposes of synthesizing the weight program for A/', we consider another sys- 
tem, say $, a formal nL-dimensional system of differential equations comprising L 
n-dimensional subsystems. With the exception that all L n-dimensional subsystems 
are constrained to have the same weight matriz, they are otherwise identical and 
decoupled. We shall use this system to determine the optimal weight program given 
L input-output samples. The resulting time program of weights is then applied to 
the original n-dimensional system A/' during normal operation. We emphasize the 
difference between this scheme and a simple L-fold replication of A/': the latter 
will yield a practically unwieldy nL x nL weight matrix sequence, and in fact will 
generally not discover the underlying map from L/to 2, discovering instead differ- 
ent maps for each input-output sample pair. By constraining the weight matrix 
sequence to be an identical n x n matrix for each subsystem during this synthesis 
phase, our scheme in essence forces the weight sequence to capture some underlying 
relationship between all the input-output pairs. This is arguably the best estimate 
of the map given the information we have. 
Using formal optimal control techniques[3], we set up a performance index to max- 
imize the correlation between the system $ output and the desired output. This 
optimization technique leads in general to a nonlinear two-point-boundary-value 
problem, and is not usually solvable analytically. For this particular performance 
index we are able to derive an analytical solution to the optimization problem. 
The optimal interconnection matrix at each time is the sum (over the index of all 
samples) of the outer products between each desired output n-vector and the cor- 
responding subsystem output. At the end of this synthesis procedure, the weight 
matrix sequence represents an optimal time-varying program for the weights of the 
n-dimensional neural network A/' that will approximate b :L/-- 2. 
We remark that in the ideal case, the weight matrix at the final time (i.e one element 
of the time sequence) corresponds to the symmetric matrix suggested empirically by 
Hopfield for associative memory applications[4]. It becomes clear that the Hopfield 
matrix is suboptimal for associative memory, being just one point on the optimal 
weight trajectory; it is optimal only in the special case where the initial conditions 
coincide exactly with the desired output. 
In Section 2 we outline the mathematical formulation and solution of the synthesis 
technique, and in Section 3 we present the learning curves. The learning curves also 
by default yield the system performance over the training samples, and we compare 
this performance to that of the outer product rule. In Section 4 we give concluding 
remarks and give the directions of our future work. 
Although the results here are derived for a specific case of the neuron state equation, 
and a specific choice of performance index, in further work we have extended the 
results to very general state equations and performance indices. 
350 Farotimi, Dembo and Kailath 
2 SYNTHESIS OF WEIGHT MATRIX TIME SEQUENCE 
Suppose we have a training set consisting of L pairs of n-dimensional vectors 
(t(r)i, 0(r)), r = 1, 2,..., L, i = 1, 2,..., n. For example, in an autoassociative sys- 
tem in which we desire to store 0(r), r = 1,2,..., L, i = 1,2,..., n, we can choose 
the O(r)i,r -- 1,2,...,L,i = 1,2,...,n to be sample points in the neighborhood of 
0(r)i in n-dimensional space. The idea here is that by training the network to map 
samples in the neighborhood of an exemplar to the exemplar, it will have devel- 
oped a map that can smoothly interpolate (or generalize) to other points around 
the exemplar that may not be in the training set. In this paper we deal with the 
issue of finding the weight matrix that transforms the neural network dynamics into 
such a map. We demonstrate through simulation results that such a map can be 
achieved. For autoassociation, and using error vectors drawn from the training set, 
we show that the method here performs better (in an error-correcting sense) than 
the outer product rule. We are still investigating the performance of the network 
in generalizing to samples outside the training set. 
We construct an n-dimensional neural network system Af to model the underlying 
input-output map according to 
= + 
(1) 
We interpret :r as the neuron activation, g(e(t)) is the neuron output, and W(t) is 
the neural network weight matrix. 
To determine the appropriate W(t), we define an nL-dimensional formal system of 
differential equations, $ 
$: = + = b 
formed by concatenating the equations for A; L times. W. (t) is block-diagonal with 
identical blocks W(t). t9 is the concatenated vector of sample desired outputs,  is 
the concatenated vector of sample inputs. 
The performance index for $ is 
min J = min { 
j=l 
The performance index is chosen to minimize the negative of the correlation between 
the (concatenated) neuron activation and the (concatenated) desired output vectors, 
or equivalently maximize the correlation between the activation and the desired 
output at the final time t f, (the term -a:.'(tl)19). Along the way from initial time 
to to final time tl, the term -z.aP(t)19 under the integral penalizes decorrelation of 
the neuron activation and the desired output. wj(t), j = 1,2,..., n are the rows of 
W(t), and/ is a positive constant. The term/- 5=x wf(t)wj(t)effects a bound 
Neural Network Weight Matrix Synthesis 351 
on the magnitude of the weights. The term 
n L n L 
j=l r=l u=l v=l 
and its meaning will be clear when we examine the optimal path later. 
assumed C  differentiable. 
Proceeding formally[3], we define the HamiltonJan: 
H 
_ 1 _2zT(t)8+Q + Zwf(t)Bwj(t) 
-  
j-1 
g(.) is 
+ x'(t) (-z(t) + w.(Og((O)) 
l(-2z'(t)8+Q+.w(t)Bwj(t))-'(t)z(t) 
=  
j=l 
(4) 
L r 
r=l j=l 
where 
T(t)= [o)(t) (x)2(t ) ... 
is the vector of Lagrange multipliers, and we have used the fact that W, (t) is block- 
diagonal with identical blocks W(t) in writing the summation of the last term in 
the second line of equation (4). The Euler-Lagrange equations are then given by 
= k' / =   - (8 + x(O) +  ."(t)x(t) (5) 
= -e (6) 
L 
= ø = r + %()((0) (7) 
Owj ?=l 
-x 
0 
From equation (7) we have 
L 
wij(t) = -/E A(r)ig(xJ (r)(t)) (8) 
Choosing 
X(t) = -8 (9) 
satisfies the final condition (6), and with some algebra we find that this choice is 
also consistent with equations (5) and (7). The optimal weight program is therefore 
L 
r=l 
This describes the weight paradigm to be applied to the n-dimensional neural net- 
work.-system A/' in order to model the underlying map described by the sample 
352 Farotimi, Dembo and Kailath 
points. A similar result can be derived for the discrete-time network z(k + 1) = 
W()O(()): 
L 
r..l 
2.1 REMARKS 
Meaning of Q. 
On the optimal path, using equation (10), it is straightforward to show that 
.Q = 
j=l 
Thus Q acts like another integral constraint term on the weights. 
The Optimal Return Function. 
The optimal return function[3], which is the value of the performance index 
on the optimal path can be shown to be 
t) = 
Thus the optimal weight matrix W(t) seeks at every instant to minimize the 
negative correlation (or maximize the correlation) on the optimal path in the 
formal system $ (and hence in the neural network Af). 
ß Comparison with outer product rule. 
It is worthwhile to compare equation (10) with the outer product rule: 
L 
w 0 = 3  
r-1 
(11) 
We see that the outer product rule is just one point on the weight trajectory 
defined by equation (10) - the point at final time t! when g(xj(r)(tl)) = 
3 LEARNING CURVES 
In our simulation we considered 14 8-dimensional vectors as the desired outputs. 
The weight synthesis or learning phase is as follows: we initialized the 112-dimensional 
formal synthesis system $ with a corrupted version of the vector set, and used equa- 
tion (10) to find the optimal 8 x 8 weight matrix sequence for an 8-dimensional 
neural network A f to correctly classify any of the corrupted 14 vectors. The weight 
sequence is recorded. This procedure is required only once for any given training 
set. After this learning is completed, the normal operation of the neural network Af 
consists in running it using the weights obtained from the synthesis phase above. 
The resulting network describes a continuous input-output map. At points belong- 
ing to the training set this map coincides with the underlying map we are trying 
to model. For points outside the training set, it performs a nonlinear interpolation 
Neural Network Weight Matrix Synthesis 353 
(generalization) the nature of which is determined by the training set as well as the 
neuron state equation. Figure 1 shows the learning procedure through time. The 
curves labeled "Optimally Trained Network" shows the behavior of two correlation 
measures as the training proceeds. One correlation measure used was the cosine 
of the angle between the desired vector (0) and the neuron activation (a) vector. 
The other correlation measure was the cosine of the angle between the desired vec- 
tor (0) and the neuron output (g(a:(/))) vector. Given our system initialization in 
equation (2), the correlation g(a(l))To more accurately represents our objective, 
although the performance index (3) reflects the correlation aTo. The reason for 
our performance index choice is that the weight trajectory yielded by g(a(t))TO 
leads the system to an all-zero, trivial equilibrium for a sigmoid g(.) (we used such 
a g(.) with saturation values at +1 and -1 in our simulations). This is not the 
case for the weight trajectory yielded by aTo. Since g(a(/)) is monotonic with a, 
;rTO represented an admissible alternative choice for the performance index. The 
results bear this out. Another possible choice is (g(a(/)) + a)To. This gives simi- 
lar results upon simulation. The correlation measures are plotted on the ordinate. 
The abscissa is the number of computer iterations. A discrete-time network with 
real-valued parameters was used. The total number of errors in the 14 8-bit binary 
{1,-1} vectors used to initialize the system was 21. This results in an average of 
1.5 errors per 8-bit vector. We note that the learning was completed in two time 
steps. Therefore, in this case at least, we see that the storage requirement is not 
intensive - only two weight matrices need to be stored during the synthesis phase. 
We note that the learning phase by default also represents the autoassociative sys- 
tem error-correcting performance over input samples drawn from lhe lraining sel. 
Therefore over the training set we can compare this performance with that of the 
outer product rule (11). By considering corrupted input vectors from the train- 
ing set, we compare the error-correcting capabilities of the two methods, nol their 
capacities to store uncorrupted vectors. In fact we see that the two weight rules 
become identical when we initialize with the true vectors (this equivalence is not a 
peculiarity of the new technique, but merely a consequence of the particular perfor- 
mance index chosen). In other words, this comparison is a test of the extent of the 
basins of attraction around the desired memories for the two techniques. Looking 
at the curves labeled "Conventional Outer Product", we see that the new technique 
performs better than the outer product rule. 
4 CONCLUSIONS AND FURTHER WORK 
We have described a technique for training neural networks based on formal tools 
from optimal control theory. For a specific example consisting of learning the input- 
output map in a training set we derived the relevant weight equations and illustrated 
the learning phase of the method. This example gives a weight rule that turns 
out to be a continuous-time generalization of the outer-product rule. Using cor- 
rupted vectors from the training set, we show that the new rule performs better 
in error-correction than the outer-product rule. Simulations on the generalization 
capaSilities of the method are ongoing and are not included in the present work. 
354 Farotimi, Dembo and Kailath 
0.4 
0.3 
0.2 
OA 
0 
I 
0.1 
0.7 
Figure 1: Learning Curves 
Although we considered a training set consisting of input-output vector pairs as 
the starting point for the procedure, a closer examination shows that this is not 
required. More generally, what is required is a performance index that reflects the 
objective of the training. Also in our ongoing work we have extended the results 
to more general forms of the state equation and the performance index. Using an 
appropriate performance index we are investigating a network for the Travelling 
Salesman Problem and related applications like Tracking and Data Association. 
References 
[1] 
[2] 
Michael A. Cohen & Stephen Grossberg, "Absolute Stability of Global Pat- 
tern Formation and Parallel Memory Storage by Competitive Neural Networks," 
IEEE Transactions on Systems, Man and Cybernetics SMC-13 (1983), 815-826. 
J. J. Hopfield & D. W. Tank, "Neural Computation of Decisions in Optimization 
Problems," Biological Cybernetics 52 (1985), 141-152. 
Arthur E. Bryson & Yu-Chi Ho, Applied Optimal Control, Hemisphere, 1975. 
J. J. Hopfield, "Neural Networks and Physical Systems with Emergent Collective 
Computational Abilities," Proceedings of the National Academy of Sciences 79 
(1982), 2554-2558. 
